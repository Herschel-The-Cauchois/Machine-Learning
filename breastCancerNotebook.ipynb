{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8614a685",
   "metadata": {},
   "source": [
    "# Machine Learning and Breast Cancer detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7dee6d",
   "metadata": {},
   "source": [
    "## Introduction and state of the Art\n",
    "\n",
    "(Hamza's part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93677708",
   "metadata": {},
   "source": [
    "## An Array of Available solution\n",
    "\n",
    "(Anthime's part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb381f0",
   "metadata": {},
   "source": [
    "## Selecting a solution\n",
    "\n",
    "The given dataset, outside of the id column that we will not use, contains a column labeling each tumor and a handful of statistical columns containing the average, worst case and standard error about various tumor metrics including : radius, texture, perimeter, area, smoothness, compactness, concavity and concave points. This immediatly presents us with the necessity to standardize and normalize the data, which we will do with the Yeo-Johnson transformation, due to the differences in units and range of each metrics.\n",
    "\n",
    "With a grand total of 24 data columns, we also have to address the high dimensionality of this data. A first step towards this was to reduce the number of columns to a more acceptable one for a model, to have just enough for it to deduce things without having too much statistical noise to confuse it. To still profit from the richness of the dataset, we have decided to train and confront three different models, each one with a different variation of metrics. I.e, we did one for all means, another one for all standard errors, and a last one for worst case. At the end of our script, we will for experimentation purposes train a model with all the standardized columns to see how it influences accuracy.\n",
    "\n",
    "As for the type of model we will use, the high dimensionality of data makes hyperplane-based or regression models less easier to wrap our head around. Our final pick was K-Nearest Neighbors, as it easily navigates through high-dimensional spaces, is quite deterministic and easily explainable to non-initiated people. It's a perfect, ready-to-use classification algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b8a47a",
   "metadata": {},
   "source": [
    "## Implementing\n",
    "\n",
    "All starts first with the importation of necessary libraries and modules, and of the dataset itself with a code snippet generously provided by the dataset host Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063044e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fetch the Croissant JSON-LD\n",
    "croissant_dataset = mlc.Dataset('https://www.kaggle.com/datasets/erdemtaha/cancer-data/croissant/download')\n",
    "\n",
    "# Check what record sets are in the dataset\n",
    "record_sets = croissant_dataset.metadata.record_sets\n",
    "print(record_sets)\n",
    "\n",
    "# Fetch the records and put them in a DataFrame\n",
    "record_set_df = pd.DataFrame(croissant_dataset.records(record_set=record_sets[0].uuid))\n",
    "record_set_df.head()\n",
    "# automatic fetching courtesy of the Kaggle platform\n",
    "\n",
    "# print(record_set_df.columns.to_list()) # Lists columns to know how they are formatted in the dataframe after importation\n",
    "record_set_df = record_set_df.convert_dtypes() # Data type auto conversion for proper handling\n",
    "record_set_df[\"Cancer_Data.csv/diagnosis\"] = record_set_df[\"Cancer_Data.csv/diagnosis\"].apply(lambda x: x.decode(\"utf-8\") if isinstance(x, bytes) else x) # Decodes diagnosis info who is encoded as bytes, turns it into string\n",
    "\n",
    "# Demands before continuing the selected n neighbors we want to launch KNN at\n",
    "n = int(input(\"Enter number of neighbors to be considered in KNN : \"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
